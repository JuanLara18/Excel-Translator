2025-02-05 17:20:51,761 - INFO - Starting Excel translation process.
2025-02-05 17:20:52,196 - INFO - Loaded input file: sample_german_data.xlsx with 20 rows.
2025-02-05 17:20:52,213 - INFO - Found 8 unique texts to translate.
2025-02-05 17:20:52,245 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a technical translator specializing in machine error messages and technical descriptions. Follow these rules:\n\n1. Translate from German to English precisely and technically\n2. Use consistent technical terminology\n3. Maintain any error codes or numbers exactly as they appear\n4. Keep punctuation that could be part of error syntax\n5. Do not add explanations or alternatives\n6. Do not modify technical terms in brackets or parentheses\n7. Preserve any variable names or placeholders exactly as they appear\n\nExample 1:\nInput: "Fehler E123: Motorüberhitzung"\nOutput: Error E123: Motor overheating\n\nExample 2:\nInput: "Wartung erforderlich: Öldruck niedrig [P045]"\nOutput: Maintenance required: Oil pressure low [P045]\n\nRespond ONLY with the direct translation, nothing else.'}, {'role': 'user', 'content': 'Translate: Auf Wiedersehen'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 150, 'temperature': 0.1}}
2025-02-05 17:20:52,592 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-05 17:20:52,592 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-05 17:20:52,857 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D7D7BF56A0>
2025-02-05 17:20:52,857 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D7D7800440> server_hostname='api.openai.com' timeout=5.0
2025-02-05 17:20:53,017 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D7D7B0FC50>
2025-02-05 17:20:53,018 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-05 17:20:53,018 - DEBUG - send_request_headers.complete
2025-02-05 17:20:53,018 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-05 17:20:53,018 - DEBUG - send_request_body.complete
2025-02-05 17:20:53,018 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-05 17:20:53,963 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 05 Feb 2025 22:20:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'd3-at-harvard'), (b'openai-processing-ms', b'638'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999647'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_9711b004570abbd60d230cfe3a0bc4be'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=KQIYiD3ZEI_20cDIKNPMHSCASqiLCsZic0eP4BCiW74-1738794054-1.0.1.1-c1TzudRp6JEn7jkpuiZCRJuOkFdagXF07JmCEkeIf2rwjxiee9wUePUFzSsX2yn2c0J79HpVQHqQ1Yb2FXDFkA; path=/; expires=Wed, 05-Feb-25 22:50:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=WspPN4djMbfHq2w1Et.Gu4B7HIUhLskzcq2888bUeFM-1738794054271-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90d64a520c9cde9b-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-05 17:20:53,965 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-05 17:20:53,965 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-05 17:20:53,966 - DEBUG - receive_response_body.complete
2025-02-05 17:20:53,966 - DEBUG - response_closed.started
2025-02-05 17:20:53,966 - DEBUG - response_closed.complete
2025-02-05 17:20:53,967 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Wed, 05 Feb 2025 22:20:54 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'd3-at-harvard'), ('openai-processing-ms', '638'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '50000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '49999647'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '0s'), ('x-request-id', 'req_9711b004570abbd60d230cfe3a0bc4be'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=KQIYiD3ZEI_20cDIKNPMHSCASqiLCsZic0eP4BCiW74-1738794054-1.0.1.1-c1TzudRp6JEn7jkpuiZCRJuOkFdagXF07JmCEkeIf2rwjxiee9wUePUFzSsX2yn2c0J79HpVQHqQ1Yb2FXDFkA; path=/; expires=Wed, 05-Feb-25 22:50:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=WspPN4djMbfHq2w1Et.Gu4B7HIUhLskzcq2888bUeFM-1738794054271-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '90d64a520c9cde9b-EWR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-05 17:20:53,967 - DEBUG - request_id: req_9711b004570abbd60d230cfe3a0bc4be
2025-02-05 17:20:53,976 - INFO - Translated: Auf Wiedersehen \u2192 Goodbye
2025-02-05 17:20:53,978 - INFO - Translated text (appears 3 times): Auf Wiedersehen \u2192 Goodbye
2025-02-05 17:20:53,982 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a technical translator specializing in machine error messages and technical descriptions. Follow these rules:\n\n1. Translate from German to English precisely and technically\n2. Use consistent technical terminology\n3. Maintain any error codes or numbers exactly as they appear\n4. Keep punctuation that could be part of error syntax\n5. Do not add explanations or alternatives\n6. Do not modify technical terms in brackets or parentheses\n7. Preserve any variable names or placeholders exactly as they appear\n\nExample 1:\nInput: "Fehler E123: Motorüberhitzung"\nOutput: Error E123: Motor overheating\n\nExample 2:\nInput: "Wartung erforderlich: Öldruck niedrig [P045]"\nOutput: Maintenance required: Oil pressure low [P045]\n\nRespond ONLY with the direct translation, nothing else.'}, {'role': 'user', 'content': 'Translate: Bitte sehr'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 150, 'temperature': 0.1}}
2025-02-05 17:20:53,982 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-05 17:20:53,983 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-05 17:20:53,983 - DEBUG - send_request_headers.complete
2025-02-05 17:20:53,983 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-05 17:20:53,983 - DEBUG - send_request_body.complete
2025-02-05 17:20:53,983 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-05 17:20:54,327 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 05 Feb 2025 22:20:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'd3-at-harvard'), (b'openai-processing-ms', b'178'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999648'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_c344730da726f4d22085130ae8843cd8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90d64a581872de9b-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-05 17:20:54,327 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-05 17:20:54,327 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-05 17:20:54,328 - DEBUG - receive_response_body.complete
2025-02-05 17:20:54,328 - DEBUG - response_closed.started
2025-02-05 17:20:54,328 - DEBUG - response_closed.complete
2025-02-05 17:20:54,328 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 05 Feb 2025 22:20:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'd3-at-harvard', 'openai-processing-ms': '178', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999648', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_c344730da726f4d22085130ae8843cd8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90d64a581872de9b-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-05 17:20:54,328 - DEBUG - request_id: req_c344730da726f4d22085130ae8843cd8
2025-02-05 17:20:54,329 - INFO - Translated: Bitte sehr \u2192 Please very
2025-02-05 17:20:54,329 - INFO - Translated text (appears 3 times): Bitte sehr \u2192 Please very
2025-02-05 17:20:54,334 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a technical translator specializing in machine error messages and technical descriptions. Follow these rules:\n\n1. Translate from German to English precisely and technically\n2. Use consistent technical terminology\n3. Maintain any error codes or numbers exactly as they appear\n4. Keep punctuation that could be part of error syntax\n5. Do not add explanations or alternatives\n6. Do not modify technical terms in brackets or parentheses\n7. Preserve any variable names or placeholders exactly as they appear\n\nExample 1:\nInput: "Fehler E123: Motorüberhitzung"\nOutput: Error E123: Motor overheating\n\nExample 2:\nInput: "Wartung erforderlich: Öldruck niedrig [P045]"\nOutput: Maintenance required: Oil pressure low [P045]\n\nRespond ONLY with the direct translation, nothing else.'}, {'role': 'user', 'content': 'Translate: Ich bin müde'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 150, 'temperature': 0.1}}
2025-02-05 17:20:54,335 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-05 17:20:54,335 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-05 17:20:54,335 - DEBUG - send_request_headers.complete
2025-02-05 17:20:54,335 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-05 17:20:54,335 - DEBUG - send_request_body.complete
2025-02-05 17:20:54,336 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-05 17:20:54,697 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 05 Feb 2025 22:20:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'd3-at-harvard'), (b'openai-processing-ms', b'170'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999647'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_8c607d51d9e88027b33f1f05ea0296b9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90d64a5a4ee7de9b-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-05 17:20:54,697 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-05 17:20:54,697 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-05 17:20:54,698 - DEBUG - receive_response_body.complete
2025-02-05 17:20:54,698 - DEBUG - response_closed.started
2025-02-05 17:20:54,698 - DEBUG - response_closed.complete
2025-02-05 17:20:54,698 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 05 Feb 2025 22:20:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'd3-at-harvard', 'openai-processing-ms': '170', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999647', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_8c607d51d9e88027b33f1f05ea0296b9', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90d64a5a4ee7de9b-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-05 17:20:54,699 - DEBUG - request_id: req_8c607d51d9e88027b33f1f05ea0296b9
2025-02-05 17:20:54,699 - INFO - Translated: Ich bin müde \u2192 I am tired
2025-02-05 17:20:54,699 - INFO - Translated text (appears 3 times): Ich bin müde \u2192 I am tired
2025-02-05 17:20:54,704 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a technical translator specializing in machine error messages and technical descriptions. Follow these rules:\n\n1. Translate from German to English precisely and technically\n2. Use consistent technical terminology\n3. Maintain any error codes or numbers exactly as they appear\n4. Keep punctuation that could be part of error syntax\n5. Do not add explanations or alternatives\n6. Do not modify technical terms in brackets or parentheses\n7. Preserve any variable names or placeholders exactly as they appear\n\nExample 1:\nInput: "Fehler E123: Motorüberhitzung"\nOutput: Error E123: Motor overheating\n\nExample 2:\nInput: "Wartung erforderlich: Öldruck niedrig [P045]"\nOutput: Maintenance required: Oil pressure low [P045]\n\nRespond ONLY with the direct translation, nothing else.'}, {'role': 'user', 'content': 'Translate: Entschuldigung'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 150, 'temperature': 0.1}}
2025-02-05 17:20:54,705 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-05 17:20:54,705 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-05 17:20:54,705 - DEBUG - send_request_headers.complete
2025-02-05 17:20:54,706 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-05 17:20:54,706 - DEBUG - send_request_body.complete
2025-02-05 17:20:54,706 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-05 17:20:55,058 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 05 Feb 2025 22:20:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'd3-at-harvard'), (b'openai-processing-ms', b'189'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999647'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_c2ab3f05be4df30d3090923bc50547c9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90d64a5c9e56de9b-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-05 17:20:55,058 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-05 17:20:55,059 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-05 17:20:55,061 - DEBUG - receive_response_body.complete
2025-02-05 17:20:55,062 - DEBUG - response_closed.started
2025-02-05 17:20:55,062 - DEBUG - response_closed.complete
2025-02-05 17:20:55,062 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 05 Feb 2025 22:20:55 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'd3-at-harvard', 'openai-processing-ms': '189', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999647', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_c2ab3f05be4df30d3090923bc50547c9', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90d64a5c9e56de9b-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-05 17:20:55,062 - DEBUG - request_id: req_c2ab3f05be4df30d3090923bc50547c9
2025-02-05 17:20:55,062 - INFO - Translated: Entschuldigung \u2192 Apology
2025-02-05 17:20:55,062 - INFO - Translated text (appears 3 times): Entschuldigung \u2192 Apology
2025-02-05 17:20:55,066 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a technical translator specializing in machine error messages and technical descriptions. Follow these rules:\n\n1. Translate from German to English precisely and technically\n2. Use consistent technical terminology\n3. Maintain any error codes or numbers exactly as they appear\n4. Keep punctuation that could be part of error syntax\n5. Do not add explanations or alternatives\n6. Do not modify technical terms in brackets or parentheses\n7. Preserve any variable names or placeholders exactly as they appear\n\nExample 1:\nInput: "Fehler E123: Motorüberhitzung"\nOutput: Error E123: Motor overheating\n\nExample 2:\nInput: "Wartung erforderlich: Öldruck niedrig [P045]"\nOutput: Maintenance required: Oil pressure low [P045]\n\nRespond ONLY with the direct translation, nothing else.'}, {'role': 'user', 'content': 'Translate: Alles klar'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 150, 'temperature': 0.1}}
2025-02-05 17:20:55,067 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-05 17:20:55,067 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-05 17:20:55,067 - DEBUG - send_request_headers.complete
2025-02-05 17:20:55,067 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-05 17:20:55,067 - DEBUG - send_request_body.complete
2025-02-05 17:20:55,067 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-05 17:20:55,795 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 05 Feb 2025 22:20:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'd3-at-harvard'), (b'openai-processing-ms', b'156'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999648'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_0737da074fbcea1d57b88a78a9de0989'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90d64a5edd80de9b-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-05 17:20:55,795 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-05 17:20:55,795 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-05 17:20:55,796 - DEBUG - receive_response_body.complete
2025-02-05 17:20:55,796 - DEBUG - response_closed.started
2025-02-05 17:20:55,796 - DEBUG - response_closed.complete
2025-02-05 17:20:55,796 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 05 Feb 2025 22:20:55 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'd3-at-harvard', 'openai-processing-ms': '156', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999648', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_0737da074fbcea1d57b88a78a9de0989', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90d64a5edd80de9b-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-05 17:20:55,796 - DEBUG - request_id: req_0737da074fbcea1d57b88a78a9de0989
2025-02-05 17:20:55,796 - INFO - Translated: Alles klar \u2192 All clear
2025-02-05 17:20:55,797 - INFO - Translated text (appears 3 times): Alles klar \u2192 All clear
2025-02-05 17:20:55,800 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a technical translator specializing in machine error messages and technical descriptions. Follow these rules:\n\n1. Translate from German to English precisely and technically\n2. Use consistent technical terminology\n3. Maintain any error codes or numbers exactly as they appear\n4. Keep punctuation that could be part of error syntax\n5. Do not add explanations or alternatives\n6. Do not modify technical terms in brackets or parentheses\n7. Preserve any variable names or placeholders exactly as they appear\n\nExample 1:\nInput: "Fehler E123: Motorüberhitzung"\nOutput: Error E123: Motor overheating\n\nExample 2:\nInput: "Wartung erforderlich: Öldruck niedrig [P045]"\nOutput: Maintenance required: Oil pressure low [P045]\n\nRespond ONLY with the direct translation, nothing else.'}, {'role': 'user', 'content': 'Translate: Wie geht es dir?'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 150, 'temperature': 0.1}}
2025-02-05 17:20:55,800 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-05 17:20:55,801 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-05 17:20:55,801 - DEBUG - send_request_headers.complete
2025-02-05 17:20:55,801 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-05 17:20:55,801 - DEBUG - send_request_body.complete
2025-02-05 17:20:55,801 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-05 17:20:56,533 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 05 Feb 2025 22:20:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'd3-at-harvard'), (b'openai-processing-ms', b'538'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999645'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_1757d025ef2c3846724e92c244884552'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90d64a636b72de9b-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-05 17:20:56,533 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-05 17:20:56,533 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-05 17:20:56,537 - DEBUG - receive_response_body.complete
2025-02-05 17:20:56,537 - DEBUG - response_closed.started
2025-02-05 17:20:56,537 - DEBUG - response_closed.complete
2025-02-05 17:20:56,537 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 05 Feb 2025 22:20:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'd3-at-harvard', 'openai-processing-ms': '538', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999645', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_1757d025ef2c3846724e92c244884552', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90d64a636b72de9b-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-05 17:20:56,537 - DEBUG - request_id: req_1757d025ef2c3846724e92c244884552
2025-02-05 17:20:56,538 - INFO - Translated: Wie geht es dir? \u2192 How are you?
2025-02-05 17:20:56,538 - INFO - Translated text (appears 2 times): Wie geht es dir? \u2192 How are you?
2025-02-05 17:20:56,542 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a technical translator specializing in machine error messages and technical descriptions. Follow these rules:\n\n1. Translate from German to English precisely and technically\n2. Use consistent technical terminology\n3. Maintain any error codes or numbers exactly as they appear\n4. Keep punctuation that could be part of error syntax\n5. Do not add explanations or alternatives\n6. Do not modify technical terms in brackets or parentheses\n7. Preserve any variable names or placeholders exactly as they appear\n\nExample 1:\nInput: "Fehler E123: Motorüberhitzung"\nOutput: Error E123: Motor overheating\n\nExample 2:\nInput: "Wartung erforderlich: Öldruck niedrig [P045]"\nOutput: Maintenance required: Oil pressure low [P045]\n\nRespond ONLY with the direct translation, nothing else.'}, {'role': 'user', 'content': 'Translate: Guten Morgen'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 150, 'temperature': 0.1}}
2025-02-05 17:20:56,543 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-05 17:20:56,543 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-05 17:20:56,543 - DEBUG - send_request_headers.complete
2025-02-05 17:20:56,543 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-05 17:20:56,543 - DEBUG - send_request_body.complete
2025-02-05 17:20:56,543 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-05 17:20:56,911 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 05 Feb 2025 22:20:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'd3-at-harvard'), (b'openai-processing-ms', b'160'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999647'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_2106cc4ed8d13727db666b31bb5d377b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90d64a680abfde9b-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-05 17:20:56,911 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-05 17:20:56,911 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-05 17:20:56,912 - DEBUG - receive_response_body.complete
2025-02-05 17:20:56,912 - DEBUG - response_closed.started
2025-02-05 17:20:56,912 - DEBUG - response_closed.complete
2025-02-05 17:20:56,912 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 05 Feb 2025 22:20:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'd3-at-harvard', 'openai-processing-ms': '160', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999647', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_2106cc4ed8d13727db666b31bb5d377b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90d64a680abfde9b-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-05 17:20:56,912 - DEBUG - request_id: req_2106cc4ed8d13727db666b31bb5d377b
2025-02-05 17:20:56,912 - INFO - Translated: Guten Morgen \u2192 Good morning
2025-02-05 17:20:56,912 - INFO - Translated text (appears 2 times): Guten Morgen \u2192 Good morning
2025-02-05 17:20:56,916 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a technical translator specializing in machine error messages and technical descriptions. Follow these rules:\n\n1. Translate from German to English precisely and technically\n2. Use consistent technical terminology\n3. Maintain any error codes or numbers exactly as they appear\n4. Keep punctuation that could be part of error syntax\n5. Do not add explanations or alternatives\n6. Do not modify technical terms in brackets or parentheses\n7. Preserve any variable names or placeholders exactly as they appear\n\nExample 1:\nInput: "Fehler E123: Motorüberhitzung"\nOutput: Error E123: Motor overheating\n\nExample 2:\nInput: "Wartung erforderlich: Öldruck niedrig [P045]"\nOutput: Maintenance required: Oil pressure low [P045]\n\nRespond ONLY with the direct translation, nothing else.'}, {'role': 'user', 'content': 'Translate: Bis später'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 150, 'temperature': 0.1}}
2025-02-05 17:20:56,916 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-05 17:20:56,916 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-05 17:20:56,917 - DEBUG - send_request_headers.complete
2025-02-05 17:20:56,917 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-05 17:20:56,917 - DEBUG - send_request_body.complete
2025-02-05 17:20:56,917 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-05 17:20:57,277 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 05 Feb 2025 22:20:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'd3-at-harvard'), (b'openai-processing-ms', b'197'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'50000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'49999648'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_b42db2e599907f5355f856accc7ec0f7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90d64a6a6ac3de9b-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-05 17:20:57,278 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-05 17:20:57,278 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-05 17:20:57,280 - DEBUG - receive_response_body.complete
2025-02-05 17:20:57,280 - DEBUG - response_closed.started
2025-02-05 17:20:57,281 - DEBUG - response_closed.complete
2025-02-05 17:20:57,281 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 05 Feb 2025 22:20:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'd3-at-harvard', 'openai-processing-ms': '197', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '50000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '49999648', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_b42db2e599907f5355f856accc7ec0f7', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '90d64a6a6ac3de9b-EWR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-05 17:20:57,281 - DEBUG - request_id: req_b42db2e599907f5355f856accc7ec0f7
2025-02-05 17:20:57,281 - INFO - Translated: Bis später \u2192 See you later
2025-02-05 17:20:57,281 - INFO - Translated text (appears 1 times): Bis später \u2192 See you later
2025-02-05 17:20:57,342 - INFO - Output Excel file saved to: translated_german_data.xlsx
2025-02-05 17:20:57,342 - INFO - Translation statistics:
2025-02-05 17:20:57,342 - INFO - Total texts: 20
2025-02-05 17:20:57,342 - INFO - Unique texts: 8
2025-02-05 17:20:57,342 - INFO - API calls saved: 12
2025-02-05 17:20:57,343 - INFO - Translation process finished in 5.58 seconds.
2025-02-05 17:20:57,450 - DEBUG - close.started
2025-02-05 17:20:57,451 - DEBUG - close.complete
